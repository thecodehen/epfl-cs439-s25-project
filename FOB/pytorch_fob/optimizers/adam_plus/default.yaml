optimizer:
  name: adam_plus
  lr_grad: 1.e-6
  lr_decay: 0.1
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.e-8
  reg_step_size: 100
  kappa_update: 1.0
  foreach: null
