task:
  name: graph
  output_dir_name: graph
  batch_size: 128  # reference implementation used 32
  target_metric: val_rocauc
  target_metric_mode: max
  max_epochs: 100
  max_steps: null
  model:  # GIN
    hidden_channels: 300
    num_layers: 5
    virtual_node: false
    dropout: 0.5
    graph_pooling: mean  # {max, mean, sum, attention, set2set}
    jumping_knowledge: last  # {last, sum}
engine:
  devices: 1
  sbatch_args:
    time: 00:30:00
optimizer:
  name: adamw_baseline
  weight_decay: 0
  lr_scheduler:
    eta_min_factor: 1.0  # reference implementation used no lr scheduling
evaluation:
  plot:
    metric: test_rocauc
    test_metric_mode: max
    format: "2.2"
    limits: [65, 80]
